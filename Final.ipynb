{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here info:\n",
    "#App ID: gB5Th31Aa7kCMDRB2yYH\n",
    "#App Code: _V3OMdtHzj0vDll0eT6JsA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import (metrics, model_selection, linear_model, preprocessing, ensemble, neighbors)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the \"crash\" data\n",
    "data = pd.read_csv(\"my_map_grid.csv\",header=7)\n",
    "\n",
    "# preprocessing\n",
    "# lowercase: http://stackoverflow.com/a/38931854\n",
    "data.columns = data.columns.str.lower()\n",
    "# remove spaces\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "# special cases\n",
    "data.columns = data.columns.str.replace('crash_i_d', 'crash_id')\n",
    "# remove whateva data\n",
    "\n",
    "# replace ['No Data','Not Applicable'] with NaN\n",
    "data.replace(to_replace='No Data', value=np.nan, inplace=True)\n",
    "data.replace(to_replace='Not Applicable', value=np.nan, inplace=True)\n",
    "\n",
    "dummies_needed_list = [\n",
    " 'day_of_week',\n",
    " 'intersection_related',\n",
    " 'light_condition',\n",
    " 'manner_of_collision',\n",
    " 'road_base_type',\n",
    " 'surface_condition',\n",
    " 'weather_condition'\n",
    "        ]\n",
    "# encode data for dummies_needed_list\n",
    "for feat in dummies_needed_list:\n",
    "    data = pd.concat([data,pd.get_dummies(data[feat],prefix=feat)],axis=1)\n",
    "    data = data.drop([feat],axis=1)\n",
    "\n",
    "#remove data that will not be usefull\n",
    "drop_columns = ['crash_id',\n",
    "                'average_daily_traffic_amount',\n",
    "                'average_daily_traffic_year',\n",
    "                'street_name',\n",
    "                'intersecting_street_name',\n",
    "                'medical_advisory_flag',\n",
    "                'object_struck']\n",
    "crash_id = data.crash_id\n",
    "data = data.drop(drop_columns,axis=1)\n",
    "\n",
    "#fill missing values\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "#split data into train/test,x/y\n",
    "np.random.seed(0)\n",
    "train, test = train_test_split(data)\n",
    "x_train = train.drop(['crash_severity'],axis=1)\n",
    "y_train = train.crash_severity\n",
    "x_test = test.drop(['crash_severity'],axis=1)\n",
    "y_test = test.crash_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-b0fe677c1447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#test models from data will need a model that can classify more than 2 response classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\weyma\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[1;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\weyma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\weyma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\weyma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#test models from data will need a model that can classify more than 2 response classes\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import http.client\n",
    "\n",
    "#conn = http.client.HTTPSConnection('https://reverse.geocoder.cit.api.here.com/6.2/reversegeocode.xml?prox=50.112,8.683&mode=retrieveAreas&app_id=gB5Th31Aa7kCMDRB2yYH&app_code=_V3OMdtHzj0vDll0eT6JsA',port=8080)\n",
    "conn = http.client.HTTPConnection('http://reverse.geocoder.cit.api.here.com/6.2',port=8080)\n",
    "#conn.request('GET','/reversegeocode.json?prox=29.42458%2C+-98.49461&app_id=gB5Th31Aa7kCMDRB2yYH&app_code=_V3OMdtHzj0vDll0eT6JsA&mode=retrieveAddresses&gen=8&language=')\n",
    "#res = conn.getresponse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"Response\":{\"MetaInfo\":{\"Timestamp\":\"2017-04-28T19:09:10.237+0000\"},\"View\":[{\"_type\":\"SearchResultsViewType\",\"ViewId\":0,\"Result\":[{\"Relevance\":1.0,\"Distance\":0.0,\"MatchLevel\":\"street\",\"MatchQuality\":{\"Country\":1.0,\"State\":1.0,\"County\":1.0,\"City\":1.0,\"District\":1.0,\"Street\":[1.0],\"PostalCode\":1.0},\"Location\":{\"LocationId\":\"NT_i0k6XnW3CNq2ac8vLrKDuC_l_843956229_L\",\"LocationType\":\"address\",\"DisplayPosition\":{\"Latitude\":29.42458,\"Longitude\":-98.49461},\"NavigationPosition\":[{\"Latitude\":29.42458,\"Longitude\":-98.49461}],\"MapView\":{\"TopLeft\":{\"Latitude\":29.42469,\"Longitude\":-98.49462},\"BottomRight\":{\"Latitude\":29.42447,\"Longitude\":-98.4946}},\"Address\":{\"Label\":\"S Flores St, San Antonio, TX 78205, United States\",\"Country\":\"USA\",\"State\":\"TX\",\"County\":\"Bexar\",\"City\":\"San Antonio\",\"District\":\"Downtown\",\"Street\":\"S Flores St\",\"PostalCode\":\"78205\",\"AdditionalData\":[{\"value\":\"United States\",\"key\":\"CountryName\"},{\"value\":\"Texas\",\"key\":\"StateName\"},{\"value\":\"Bexar\",\"key\":\"CountyName\"},{\"value\":\"N\",\"key\":\"PostalCodeType\"}]},\"MapReference\":{\"ReferenceId\":\"843956229\",\"MapId\":\"NAAM17107\",\"MapVersion\":\"Q1/2017\",\"MapReleaseDate\":\"2017-04-18\",\"Spot\":0.5,\"SideOfStreet\":\"neither\",\"CountryId\":\"21000001\",\"StateId\":\"21015214\",\"CountyId\":\"21015293\",\"CityId\":\"21015312\"}}}]}]}}'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlopen('http://reverse.geocoder.cit.api.here.com/6.2/reversegeocode.json?prox=29.42458%2C+-98.49461&app_id=gB5Th31Aa7kCMDRB2yYH&app_code=_V3OMdtHzj0vDll0eT6JsA&mode=retrieveAddresses&gen=8&language=').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://reverse.geocoder.cit.api.here.com/6.2/reversegeocode.json?prox=29.42458%2C+-98.49461&app_id=gB5Th31Aa7kCMDRB2yYH&app_code=_V3OMdtHzj0vDll0eT6JsA&mode=retrieveAddresses&gen=8&language='"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geocoder\n",
    "\n",
    "g = geocoder.here([29.42458,-98.49461],app_id='gB5Th31Aa7kCMDRB2yYH',app_code='_V3OMdtHzj0vDll0eT6JsA',method='reverse',mode='retrieveAll',responseattributes='SpeedLimitType')\n",
    "g.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert 'Wet' 'Dry' to '1' '0'\n",
    "data['surface_condition'] = data['surface_condition'].factorize()[0]\n",
    "# DOC: rename col http://stackoverflow.com/a/11346337\n",
    "data.rename(columns={'surface_condition':'surface_wet'})\n",
    "# print number of unique\n",
    "for colname in data.columns:\n",
    "    print(\"% 4d : %s\" % (len(data[colname].unique()), colname))\n",
    "# remove data which is has no importance\n",
    "# better to drop cols with all NaN and convert \"unimportant\" data to NaN\n",
    "#  - can't universally decide to drop col just based on uniqueness\n",
    "# e.g. all of object_struck is 'Not Applicable' and useless, but if surface_condition had only one value \"dry\" this would be important\n",
    "# ? for colname in data.columns:\n",
    "# colname = 'object_struck'\n",
    "# if(len(data[colname].unique()) == 1):\n",
    "#   print(\"-I-: dropping %s for having all homogenous values %s\", (colname, data[colname].unique()[0]))\n",
    "#   data.drop(colname,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "if(1):\n",
    "  data.describe()\n",
    "  data.hist()\n",
    "  data.corr().plot() # TODO: seaborn\n",
    "  plt.show()\n",
    "else:\n",
    "  print(\"-I-: Skipping...\")\n",
    "\n",
    "pairplot_var_list = [\n",
    "# 'crash_id',\n",
    " 'average_daily_traffic_amount',\n",
    " 'average_daily_traffic_year',\n",
    " 'crash_death_count',\n",
    "# 'crash_incapacitating_injury_count',\n",
    "# 'crash_non-incapacitating_injury_count',\n",
    "# 'crash_not_injured_count',\n",
    "# 'crash_possible_injury_count',\n",
    " 'crash_severity',\n",
    " 'crash_time',\n",
    " 'crash_year',\n",
    " 'day_of_week',\n",
    "# 'intersecting_street_name',\n",
    " 'intersection_related',\n",
    "# 'latitude',\n",
    " 'light_condition',\n",
    "# 'longitude',\n",
    " 'manner_of_collision',\n",
    " 'medical_advisory_flag',\n",
    " 'number_of_entering_roads',\n",
    " 'number_of_lanes',\n",
    "# 'object_struck',\n",
    " 'road_base_type',\n",
    " 'speed_limit',\n",
    "# 'street_name',\n",
    " 'surface_condition'\n",
    " ]\n",
    "\n",
    "# tmp disable\n",
    "if(0):\n",
    "    sns.pairplot(data, vars=pairplot_var_list)\n",
    "    plt.show()\n",
    "\n",
    "# alternative visualisation\n",
    "datapt = data.pivot_table(values=['crash_death_count','crash_incapacitating_injury_count','crash_non-incapacitating_injury_count'], index=['speed_limit','crash_time'])\n",
    "print(datapt)\n",
    "\n",
    "pp.pprint(list(pd.get_dummies(data[dummies_needed_list]).columns))\n",
    "pp.pprint(list(pd.get_dummies(data[dummies_needed_list]).columns.str.replace('[,\\s]+','_').str.lower()))\n",
    "'''\n",
    " 'Dark, Lighted', 'dark_lighted_yes'\n",
    " 'Dark, Not Lighted', 'dark_lighted_no'\n",
    " 'Dark, Unknown Lighting', 'dark_lighted_unknown'\n",
    " 'Dawn',\n",
    " 'Daylight',\n",
    " 'Dusk',\n",
    " 'Unknown',\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
